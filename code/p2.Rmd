---
title: "Práctica 2: Limpieza y validación de datos"
author: "Raúl Sánchez"
date: "20/12/2018"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
    number_sections: yes
   
  html_document:
    css: style.css
    highlight: tango
    number_sections: yes
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 \newpage
 
# Descripción del data set y objetivos

## Objetivo de análisis

A partir de datos disponibles sobre nutrientes que componen los alimentos y su calificación nutricional se plantea una tarea de aprendizaje supervisado de clasificación, se trata de responder a partir de los nutrientes si un alimento es saludable o no según su valor nutricional etiquetándolos de la **A** a la **E**. La pregunta a responder será por tanto, ¿A que categoría pertenece este alimento? Para ello se utiliza un algoritmo de clasificación basado en redes neuronales por su precisión en este tipo de tareas. Existe en la página openfoodfacts.org una fórmula que es la qué se usa para calificar los alimentos, la importacia de este problema planteado viene de la posibilidad de crear un modelo de clasificación en el cual ante la falta de datos en determinados nutrientes se pueda igualmente clasificar los alimentos de manera precisa.

```{r echo=FALSE, fig.cap="A caption", out.width = '100%'}
#knitr::include_graphics("nutriscore-a.png")
```

## Descripción de los datos
Disponemos del conjunto de datos obtenido en la práctica 1 de la asignatura, el conjunto consiste en los datos obtenidos de la página web openfoodfacts.org, la web contiene una gran información relativa a productos alimenticios que se distribuyen alrededor del mundo. Entre los datos de la web se encuentran los datos de composición de los diferentes nutrientes que forman un producto alimenticio, una imagen del producto, un código de barras, fecha inclusión en la base de datos, marca, donde se fabrica, una imagen de la composición detallada en el proucto, su categoría, a parte de muchos otros y finalmente una calificación nutricional del mismo en función de sus características que varía de A a E. La web se nutre de las aportaciones que hacen sus usuarios en los diferentes países del mundo. Es por ello que se observa que muchos campos de diferentes productos se encuentran vacíos o con imágenes que no han sido cargadas o incluso productos que contienen únicamente el nombre comercial de este. 

Nuestro conjunto consta de un archivo de texto .csv, nombre de archivo **es_food_nutrients.csv** que contiene los valores separados por coma, almacenados en formato tabla, las variables representadas en las columnas y las filas identifican las observaciones. En concreto contiene los datos relativos a 8215 observaciones, productos alimenticios, y 16 variables, características del producto. Y el conjunto de imágenes de imágenes de los productos almacenados en formato jpg en carpeta adjunta es_images.

Variables archivo **es_food_nutrients.csv**: 

* **Name**: Nombre del producto.
* **Energy**: Valor energético del alimento, contiene dos valores en diferentes medidas, kilocalorias (kcal) y kilojulios (kj).
* **Fat**: Contenido en gramos de grasas.
* **Saturated fat**: Contenido en gramos de grasas saturadas.
* **Carbohidrate**: Contenido en gramos de carbohidratos.
* **Sugars**: Contenido en gramos de azúcares.
* **Fiber**: Contenido en gramos de fibra.
* **Proteins**: Contenido en gramos de proteinas.
* **Salt**: Contenido en gramos de sales.
* **Sodium**: Contenido en gramos de sodio.
* **Alcohol**: Contenido en % vol. de alcohol.
* **Zinc**: Contenido en miligramos de zinc
* **Magnesium**: Contenido en miligramos de magnesio.
* **Omega3**: Contenido en gramos de grasas Omega 3.
* **Score**: Clasificación nutricional del producto. 
* **Img**: Nombre de la imagen descargada relacionada con el producto.

Los valores de las diferentes variables muestra el contenido por cada 100 gr./ml. de producto.
<Br><Br>


# Integración y selección de datos a analizar

Se cargan los datos del archivo **es_food_nutrients.csv** mediante el comando de R y se almacena en el objeto **data**. 

```{r}
data <- read.csv("es_food_nutrients.csv", na.strings=c("Na"))

head(data,3)
str(data)
```

Tras un análisis preliminar de la estructura de los datos importados, como se ha dicho, el conjunto consta de 8215 observaciones y 16 variables.Son todas las variables de tipo categórico, contienen valores junto con la unidad de medidad, ya sea g, mg, % vol, ... que habrá que eliminar. Se observa la existencia de NA's en diferentes variables. 

# Limpieza de los datos

## Conversión de tipos.

Para poder trabajar con los datos se deben convertir a tipos numéricos las variables ya que se han importado todas de tipo categórico, en las siguientes transformaciones se convertirán las variables, excepto **Name**, **Img** y **Score**, a variables de tipo cuantitativas continuas y se eliminarán las unidades de medida g y mg. La variable **Energy** se puede observar que contiene la medida en dos unidades kilojulios y kilocalorías, se prescindirá de la medida kcal debido a que esta medida está cayendo en desuso en ámbitos de la nutrición donde se usa más la medida de kilojulios. Se sustituirá el separador decimal "," por ".". Se eleminarán tambien caracteres "~", ">" y "<" de los valores.

```{r}
# Valor Energy
data$Energy <- gsub(" kj([()0-9 kcal]+)","",data$Energy)

# Elimina caracteres
cols <- c(1, 15, 16)
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub(" g", "", y)))
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub(" mg", "", y)))
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub(" % vol", "", y)))
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub("~ ", "", y)))
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub("< ", "", y)))
data[,-cols] <- as.data.frame(apply(data[,-cols], 2, function(y) gsub("> ", "", y)))

data[, -cols] <- as.data.frame(apply(data[, -cols], 2, 
                                     function(y) as.numeric(gsub(",", ".", y))))
summary(data[, -cols])
```


## Análisis de elementos vacíos o nulos.
Se analiza a continuación la existencia de vacíos en el conjunto de datos. 
```{r}
# NA's
na.data <- sapply(data, function(y) sum(length(which(is.na(y)))))
# Representación
barplot(na.data, main="NA's por variable",las= 2)
```

Se observa la existencia de numerosos casos de valores desconocidos en todas las variables del conjunto de datos, en primer lugar se detecta que la variable **score**, que se corresponde con la clase a clasificar en nuestro estudio, cuenta con alrededor el 50% de las observaciones sin valor conocido, al no tener utilidad las observaciones que no se pueden clasificar se opta por la eliminación de estas observaciones. Hay cuatro variables **alcohol**, **Zinc**, **Magnesium** y **Omega3** que cuenta con prácticamente el 100% de valores ausentes. A continuación se muestra la existencia de valores vacíos tras eliminar las observaciones que cuentan con NA en la variable **Score** 

```{r}
# Elimina observaciones Score = Na
data_clean  <- subset(data, Score != "NA")
x_na.data <- sapply(data_clean, function(y) sum(length(which(is.na(y)))))
barplot(x_na.data, main="NA's por variable ",las= 2)
```

Se observa que con la eliminiación de las observaciones con variable **Score = NA** se han eliminado también la mayoría de vacíos en las variables **Energy, Fat, Saturated_fat, Carbohidrate, Sugars Proteins, Salt y Sodium**, lo cual nos facilita la decisión de eliminación de variables con altos casos de presencia de NA. A partir de estos datos se decide eliminar las variables que tiene alrededor del 100% de NA's, **alcohol**, **Zinc**, **Nagnesium** y **Omega3** y con un porcentaje muy elevado también  **Fiber**, donde probablemente no daría buenos resultados la imputación a aplicar debido a la elevada ausencia de valores. Se elimina también las variables **Img** y **Name**, que no tienen interés para el posterior estudio.

Se eliminan a continuación las variables indicadas y se muestra el número de observaciones con valores Na por columna: 

```{r}
# Eliminación variables Alcohol, Zinc, Magnesium, Omega3, Fiber, Img y Name
data_clean <- data_clean[, -c(1, 7, 11:14, 16)]

sapply(data_clean, function(y) sum(length(which(is.na(y)))))
```

Existen varios métodos para tratar los casos en los qué existen valores ausentes en los datos, se puede ver que son muy pocos los casos en los qué esto pasa, la variable con mayor número de valores ausuentes es **Carbohydrate** que apenas tiene 10 casos. Se podría eliminar las observaciones ya que representan un porcentaje ínfimo respecto al total que son 3939. Lo ideal sería en este caso imputar los valores por grupos de productos, ya que existen artículos como la sal que contienen grandes cantidades de sodio y otro tipo de productos que no contienen, pero no existe una categorización de los alimentos que se pueda utilizar. 

Por ello, se imputará los casos existentes mediante el método kNN, método basado en distancias, que se basa en la identificación de las k observaciones más cercanas al valor a tratar e imputa la media ponderada basada en estas observaciones. A continuación se puede visualizar diferentes medidas de dispersión y tendencia central de las distribuciones de cada variable y se observa, como era de esperar, que las varaciones han sido mínimas.


```{r message=FALSE, warning=FALSE}
library(VIM)
library(psych)

# Imputación
imp_data_clean <- kNN(data_clean)[1:8]

# Cáculo estmadores
f <- function(x) {
      c(Mean = mean(x, na.rm = TRUE), Median = median(x, na.rm = TRUE), 
        SD = sd(x, na.rm = TRUE), RIC = IQR(x, na.rm = TRUE))
}

# Tablas comparación estimadores
est_table<-sapply(data_clean[1:8], f)
knitr::kable(est_table, caption = "Estimadores con datos sin imputar")

est_table<-sapply(imp_data_clean, f)
knitr::kable(est_table, caption = "Estimadores con datos imputados")

data_clean[1:8] <-imp_data_clean
```


## Identificación y tratamiento de valores extremos.

A continuación se trata de detectar la existencia de valores extremos en las variables, pueden ser varias las causas que los provocan, y por otro lado pueden causar errores en análisis posteriores como correlaciones o en modelos de predicción. Etiquetar como valor extremo o outlier un valor requiere un análisis más profundo, ya que, como se ha comentado antes un producto como la sal tendrá una gran cantidad de sodio y será normal comparado con otros productos similares pero en este caso se tienen en cuenta todos los productos disponibles sin categorizar, lo cual puede identificar valores extremos ciertas observaciones y llevar a su descarte provocando pérdida de información valiosa. 

```{r}
# N valores extremos
out_f <- function(x) {
      length(boxplot.stats(x)$out)
}

nout_table<-sapply(data_clean[1:8], out_f)
knitr::kable(nout_table, caption = "Numero de valores detectados como extreme scores")
```

De la tabla 3 se desprende el gran número de valores detectados como outliers, si se optara por la eliminación de las observaciones como método de tratamiento se perdería gran parte de los datos. Este elevado número se debe a las características de los productos existentes, ya comentado anteriormente, como ejemplo se observa en la tabla 3 las variables **Salt** y **Sodium** que tienen el mismo número de outliers (229), lo cual nos indica que estos productos tienen estas características en los nutrientes que los diferencian del resto catalogándolos como outliers, y sean no posibles errores que sucedieran en la toma de datos. Es por esto que se decide mantener las observaciones, también teniendo en cuenta que los datos provienen de una base de datos pública que se actualiza mediante la actividad de los usuarios y es fácil que los posibles errores en medidas se corrijan regularmente. En anexo 1 se encuentra el listado de todos los valores detectados como outliers por variable.

## Almacenamiento de datos procesados

Los datos tratados y limpios se encuentran ya listos para ser utilizados en los análisis de clasificació previstos, se almacenan en el archivo **es_food_nutrients_clean.csv**

```{r}
write.csv(data_clean, "es_food_nutrients_clean.csv")
```

# Análisis de los datos

## Planificación del análisis a aplicar (Selección de datos).

Se analizará el conjunto total de datos preprocesados, para la llevar a cabo el modelo de clasificación se dividará los datos en dos grupos, entrenamiento y test, se destina el 70% de las observaciones para entrenamiento y el 30% restante para test de la clasificación y así evaluar su precisión. Previamente se codifica la clases **Score** a valores numéricos, "A"="5", "B"="4", "C"="3", "D"="2", "E"="1", a continuación se normalizan los datos mediante técnica min-max como requiere el modelo de red neuronal, rango de valores entre 0 y 1.


```{r}
library(plyr)
# Codififcación clase Score
data_m <- data_clean
data_m$Score <- as.numeric(revalue(data_m$Score, 
                                c("A"="5", "B"="4","C"="3", "D"="2", "E"="1")))
# Escalado
maxs <- apply(data_m, 2, max) 
mins <- apply(data_m, 2, min)
scaled.data_m <- as.data.frame(scale(data_m, center = mins, scale = maxs - mins))

# Preparación conjuntos 70 train-30 test
samplesize = 0.70 * nrow(data_m)
set.seed(40)
indexA = sample( seq_len ( nrow ( data_m)), size = samplesize )
data.train = data_m[ indexA,]
data.test = data_m[ -indexA,]

scaled.data.train = scaled.data_m[ indexA,] #70% 
scaled.data.test = scaled.data_m[ -indexA,] #30%
```

## Comprobación de la normalidad y homogeneidad de la varianza.

Para comprobar la normalidad de las distribuciones de las diferentes variables se usa el método Shapiro-Wilk test, se muestran a continuación los resultados del p.value obtenidos del test de las variables, en todos los casos es menor al nivel de significación, lo cual indicaría la no normalidad de las distribuciones de las muestras. Aspecto que también se puede observar al analizar los gráficos QQ norm de cada una de las variables. 


```{r message=FALSE, warning=FALSE}
library(ggplot2)

# p.value variables
test_f <- function(x) {
      shapiro.test(x)$p.value
}

t_table<-sapply(data_clean[1:8], test_f)
t_table

par(mfrow=c(2,4))

qqnorm(data_clean$Sugars, pch = 1, frame = FALSE, main ="Sugars")
qqline(data_clean$Sugars, col = "steelblue", lwd = 2)
qqnorm(data_clean$Energy, pch = 1, frame = FALSE, main ="Energy")
qqline(data_clean$Energy, col = "steelblue", lwd = 2)
qqnorm(data_clean$Salt, pch = 1, frame = FALSE, main ="Salt")
qqline(data_clean$Salt, col = "steelblue", lwd = 2)
qqnorm(data_clean$Fat, pch = 1, frame = FALSE, main ="Fat")
qqline(data_clean$Fat, col = "steelblue", lwd = 2)
qqnorm(data_clean$Proteins, pch = 1, frame = FALSE, main ="Proteins")
qqline(data_clean$Proteins, col = "steelblue", lwd = 2)
qqnorm(data_clean$Carbohydrate, pch = 1, frame = FALSE, main ="Carbohydrate")
qqline(data_clean$Carbohydrate, col = "steelblue", lwd = 2)
qqnorm(data_clean$Saturated_fat, pch = 1, frame = FALSE, main ="Sat_Fat")
qqline(data_clean$Saturated_fat, col = "steelblue", lwd = 2)
qqnorm(data_clean$Sodium, pch = 1, frame = FALSE, main ="Sodium")
qqline(data_clean$Sodium, col = "steelblue", lwd = 2)

```

Respecto a la varianza se realiza a continuación el test levene, ya que este no rquiere normalidad en los datos.Se evalua en el test la hipotesis que la varianza de las poblaciones analizadas es igual (homogeneidad de varianza), si el p-value es menor a 0.05 entonces se rechaza la hipótesis y se puede afirmar que no son homogeneas. 

Se obtiene a continuación el p-value de los test de cada variable del conjunto con respecto a la variable clase Score, a la vista de estos se descarta la hipótesis nula indicando que las varianzas no son iguales en todos los casos:


```{r message=FALSE, warning=FALSE}
library(car)
lev_f <- function(x) {
      leveneTest(x ~ Score, data = data_clean)$`Pr(>F)`[1]
}
lev_table<-sapply(data_clean[1:8], lev_f)
lev_table
```


## Pruebas estadísticas
### Test de correlación variables
Se investiga a continuación la dependencia entre los nutrientes del data set mediante una matriz de correlación. 
```{r message=FALSE, warning=FALSE}
library(corrplot)
cor_d <- round(cor(data_m, use="complete.obs", method="kendall"), 3)#data_clean[1:8]
knitr::kable(cor_d, caption = "Matriz de correlación")
corrplot(cor_d, method = "ellipse")

```

Como se esperaba se observa una correlación casi perfecta positiva entre las variables **Salt** y **Sodium** de valor 0.998, se observa también una fuerte correlación positiva de 0.799 entre las variables **Fat** y **Saturated_fat**. 

A continuación se analiza mediante la función cor.test la hipótesis nula, que no hay asociación entre las variables, para ello se usa el test correlación no paramétrica de Kendall dada la no normalidad de las distribuciones, y vemos que para el par **Salt** y **Sodium** el p-valor está por debajo del nivel de significación 0.05, por lo tanto podemos concluir que las variables están significativamente correlacionadas. Por lo tanto no se incluirá para siguientes análisis una de las variables del par analizado, **Sodium**.

```{r}
cor.test(data_m$Salt, data_m$Sodium, method = "kendall")
```

### Entrenamiento modelo red neuronal
Para el entrenamiento de la red neuronal se elige una topgrafía de dos capas, la primera formada por 5 neuronas, siguiendo la "norma" de los 2/3 de las variables de entrada, la segunda consta de 3 neuronas y finalmente una neurona de salida donde se obtiene el resultado de la clasificación. Una vez elegida la topografia y las características de la red neuronal se entrena con el conjunto datos de entrenamiento anteriormente seleccionado.
```{r}

library(neuralnet)

#Formula 
feats <- names(data_m[1:7])
f <- paste(feats,collapse=' + ') 
f <- paste("Score ~",f)
f <- as.formula(f)

nn <- neuralnet(f,scaled.data.train,hidden=c(5:3),lifesign = "full", threshold = 0.05
                , linear.output=FALSE, stepmax=1e6)
```


# Resultados

Se representan a continuación los resultados obtenidos una vez aplicado el modelo de clasificación de los alimentos en base a sus nutrientes. Se evalúa la precisión de las predicciones mediante la matriz de confusión siguiente:

```{r message=FALSE, warning=FALSE}
library(NeuralNetTools)

predict_test <- compute(nn,scaled.data.test[1:7])

predict_test_ = predict_test$net.result * (max(data_m$Score) - min(data_m$Score)) + 
  min(data_m$Score) 
test.r <- (scaled.data.test$Score)*(max(data_m$Score)-min(data_m$Score))+min(data_m$Score)

predict_testnn_<- sapply(predict_test_,round,digits=0) 
knitr::kable(table(data.test$Score,predict_testnn_), caption = "Matriz de confusion modelo nn")
```

De la matriz de confusión de la predicción se desprenden los siguientes resultados:

* $ERR =\frac{392}{1182}= 0.331$ (missclassification error)
* $ACC = 1- ERR = 0.668$ (Classification accuracy)

Lo cual indica una precisión del 66.8 % en la clasificación. 

```{r}
mosaicplot(table(predict_testnn_, data.test$Score), xlab='Real value', ylab='Prediction',
           main='Mosaic Plot nn ', shade = T)
```

En el siguente gráfico se puede observar la importancia de cada una de las variables en el modelo a la hora de clasificar un alimento como saludable o no, es decir que son más influyentes o menos, las más influyentes en el sentido negativo son las variables **Saturated_fat**, **Energy** y **proteins**, en sentido positivo tenemos la variable **Sugars**.

``` {r}
# Variable importance
olden(nn)

```

# Conclusiones

A la vista de los resultados se puede decir que el clasificador no es bueno, con una precisión de clasificación de un 66.8%, es muy alta la tasa de error que se producce. Se observa que los errores de clasificación en su mayoría se producen en categorías contiguas, siendo 30 del total los errores de clasificación más allá de la categoría contigua, por ejemplo que un producto sea de calificación nutricional A y se clasifique como C, D o E. 

Será necesario investigar la mejora del modelo para aumentar la precisión, ya sea incluyendo las variables que se eliminaron en fases anteriores por falta de datos, mejorando el proceso de imputación de valores ausentes (que son muchos) o evaluando otros algoritmos de clasificación que se ajusten mejor a las características de esta tarea.


# Anéxos: 
## Anexo 1: Valores extremos identificados por variable.
```{r}
# outliers variabless
boxplot.stats(data_clean$Energy)$out
boxplot.stats(data_clean$Fat)$out
boxplot.stats(data_clean$Saturated_fat)$out
boxplot.stats(data_clean$Carbohydrate)$out
boxplot.stats(data_clean$Sugars)$out
boxplot.stats(data_clean$Proteins)$out
boxplot.stats(data_clean$Salt)$out
boxplot.stats(data_clean$Sodium)$out

```

***

                Tipologia i cicle de vida de dades - Máster de Ciencia de datos. 
